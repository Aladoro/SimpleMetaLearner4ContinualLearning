defaults:
  - _self_
  - architecture@_global_: anml_original
learner_name: optim_rln/${architecture_name}_arch


fixed_rln: false
clip_meta_gradient:

learner:
  _target_: learning_networks.OriginalLearningNetwork
  networks: ${networks}
  neuromodulation: false
  log_meta_gradient_every: ${log_meta_gradient_every}


freeze_components: ['rln_layers']
reinit_components: ['pln_layers']

log_meta_gradient_every: -1

eval_kwargs:
  freeze_components: ${freeze_components}
  reinit_components: ${reinit_components}
  learner_kwargs:
    inner_params:
  optimizer:
    _target_: training_utils.torch.optim.Adam
    lr: 1e-3

